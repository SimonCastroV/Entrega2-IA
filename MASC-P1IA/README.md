 
**Hecho por Simon Castro**  


## üìç Punto 1 ‚Äì Modelo de Aprendizaje Supervisado Cl√°sico  

### üìä Dataset Seleccionado
- **Nombre:** Titanic - Machine Learning from Disaster (Kaggle)  
- **Tipo de problema:** Clasificaci√≥n binaria (Sobrevivi√≥ / No sobrevivi√≥)  
- **N√∫mero de filas:** 891  
- **N√∫mero de columnas originales:** 12  

---

### üßπ Preprocesamiento Realizado
1. **Eliminaci√≥n de columnas irrelevantes:** `PassengerId`, `Name`, `Ticket`, `Cabin`.  
2. **Manejo de valores nulos:**
   - `Age` ‚Üí reemplazado por la **media**.
   - `Embarked` ‚Üí reemplazado por la **moda**.
3. **Codificaci√≥n de variables categ√≥ricas:** OneHotEncoding para `Sex` y `Embarked`.  
4. **Normalizaci√≥n:** `StandardScaler` aplicado a las variables num√©ricas.  
5. **Divisi√≥n del dataset:** 80% entrenamiento, 20% prueba.  

---

### ü§ñ Modelo Aplicado
Se utiliz√≥ un **Random Forest Classifier** con:
- `n_estimators=100`  
- `random_state=42`

---

### üìà Resultados Obtenidos
- **Accuracy:** `0.8101`
- **Matriz de Confusi√≥n:**

![Matriz de Confusi√≥n](matriz_confusion.png)

- **Reporte de Clasificaci√≥n:**

Reporte de clasificaci√≥n:
               precision    recall  f1-score   support

           0       0.82      0.87      0.84       105
           1       0.79      0.73      0.76        74

    accuracy                           0.81       179
   macro avg       0.81      0.80      0.80       179
weighted avg       0.81      0.81      0.81       179
---
### üìù Conclusiones
- El modelo obtuvo un **accuracy del 0.8101%**, mostrando un buen rendimiento para la clasificaci√≥n de pasajeros.
- Random Forest maneja bien variables mixtas (categ√≥ricas y num√©ricas) sin requerir demasiado preprocesamiento.  
  
